{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install waymo-open-dataset-tf-2-11-0==1.6.1\n",
        "!pip install timm\n",
        "\n",
        "import math\n",
        "import os\n",
        "import uuid\n",
        "import time\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "import matplotlib as plt\n",
        "\n",
        "\n",
        "from google.protobuf import text_format\n",
        "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
        "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
        "from waymo_open_dataset.protos import motion_metrics_pb2"
      ],
      "metadata": {
        "id": "cwukYlCJmJh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GummaeN/WaymoOpenMotionPred2023"
      ],
      "metadata": {
        "id": "Y9g1OXhzQFNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/WaymoOpenMotionPred2023/src')\n",
        "from tf_features import roadgraph_features, get_tffeatures\n",
        "import rasterize"
      ],
      "metadata": {
        "id": "pOVr2c2IgQEx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C91Ok8axqUmC",
        "outputId": "92935584-966a-4b49-9112-48c94a34e8de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature description for tf_records\n",
        "features_description = get_tffeatures()"
      ],
      "metadata": {
        "id": "KRknvm2zU48u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tf_files(dir, features_description):\n",
        "  files = glob.glob(dir, recursive=False)\n",
        "  print(f\"Number of tf_example files: {len(files)}\")\n",
        "\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(files, compression_type='')\n",
        "  data = next(dataset.as_numpy_iterator())\n",
        "  parsed = tf.io.parse_single_example(data, features_description)\n",
        "\n",
        "  print(f\"Len of scene: {len(parsed)}\")\n",
        "  print(f\"Keys: {parsed.keys()}\")\n",
        "\n",
        "\n",
        "  print(f\"\\nCurrent frames: {len(parsed['state/current/x'][0])}\")\n",
        "  print(f\"Past frames: {len(parsed['state/past/x'][0])}\")\n",
        "  print(f\"Future frames: {len(parsed['state/future/x'][0])}\")\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "HFNzLICxkWu9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/MyDrive/WaymoOpenDataset/Motion2023/train/'\n",
        "file_pattern = 'uncompressed_tf_example_training_training_tfexample.tfrecord-00*'\n",
        "dataset = load_tf_files(dir+file_pattern,features_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY1rCAtvkqbW",
        "outputId": "e47771cc-8413-42be-e5b3-fa47f4581d02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tf_example files: 50\n",
            "Len of scene: 63\n",
            "Keys: dict_keys(['roadgraph_samples/dir', 'roadgraph_samples/id', 'roadgraph_samples/type', 'roadgraph_samples/valid', 'roadgraph_samples/xyz', 'scenario/id', 'state/current/bbox_yaw', 'state/current/height', 'state/current/length', 'state/current/timestamp_micros', 'state/current/valid', 'state/current/vel_yaw', 'state/current/velocity_x', 'state/current/velocity_y', 'state/current/width', 'state/current/x', 'state/current/y', 'state/current/z', 'state/future/bbox_yaw', 'state/future/height', 'state/future/length', 'state/future/timestamp_micros', 'state/future/valid', 'state/future/vel_yaw', 'state/future/velocity_x', 'state/future/velocity_y', 'state/future/width', 'state/future/x', 'state/future/y', 'state/future/z', 'state/id', 'state/is_sdc', 'state/past/bbox_yaw', 'state/past/height', 'state/past/length', 'state/past/timestamp_micros', 'state/past/valid', 'state/past/vel_yaw', 'state/past/velocity_x', 'state/past/velocity_y', 'state/past/width', 'state/past/x', 'state/past/y', 'state/past/z', 'state/tracks_to_predict', 'state/type', 'traffic_light_state/current/id', 'traffic_light_state/current/state', 'traffic_light_state/current/valid', 'traffic_light_state/current/x', 'traffic_light_state/current/y', 'traffic_light_state/current/z', 'traffic_light_state/future/id', 'traffic_light_state/future/state', 'traffic_light_state/future/valid', 'traffic_light_state/future/x', 'traffic_light_state/future/y', 'traffic_light_state/future/z', 'traffic_light_state/past/state', 'traffic_light_state/past/valid', 'traffic_light_state/past/x', 'traffic_light_state/past/y', 'traffic_light_state/past/z'])\n",
            "\n",
            "Current frames: 1\n",
            "Past frames: 10\n",
            "Future frames: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_it = dataset.as_numpy_iterator()\n",
        "os.makedirs('/content/traintar')\n",
        "\n",
        "for i, data in enumerate(data_it):\n",
        "\n",
        "  if i % 200 == 9:\n",
        "    print(f\"Scenario:{i}\")\n",
        "\n",
        "  parsed = tf.io.parse_single_example(data, features_description)\n",
        "  params = rasterize.load_params(parsed)\n",
        "\n",
        "  for i in range(len(params['tracks_to_pred'])):\n",
        "    if params['tracks_to_pred'][i] > 0:\n",
        "      track_to_pred = np.zeros(128)\n",
        "      track_to_pred[i] = 1\n",
        "      raster = rasterize.rasterize(params,track_to_pred)\n",
        "      rasterize.save_raster(raster,i)"
      ],
      "metadata": {
        "id": "xRCWQV4ji7Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zcvf 'train.tar.gz' -C / content/traintar\n",
        "from google.colab import files\n",
        "files.download('/content/train.tar.gz')\n"
      ],
      "metadata": {
        "id": "peTJ1krQPA-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}